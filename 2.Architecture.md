# Architecture

## Spark design
Spark is a distributed parallel data-processing framework and bears many similarities to the traditional MapReduce framework. 
***Spark has the same leader-worker architecture as MapReduce, the leader process coordinates and distributes work to be performed among work processes.*** 
These two kinds of processes are formally called the ***driver and the executor***.


### Driver
*The driver is the leader process that manages the execution of a Spark job.
It is responsible for maintaining the overall state of the Spark application, responding to a user's program or input and analyzing, 
distributing and scheduling work among executor processes. 
The driver process is in essence the heart of the Spark application and maintains all application related information during an application's lifetime.*

Spark Driver converts **Spark operations into DAG computations** and schedules and distributes them as tasks across the Spark executors. 
The Spark Driver accesses the distributed components in the cluster, including the executors and the cluster manager, via the SparkSession. 
You can consider the SparkSession to be a single point of entry and access to all Spark operations and data. Through SparkSession we can read from data sources, write DataFrames or Datasets, create runtime JVM params, etc. In essence, SparkSession is the unified conduit to all of Spark functionality. If we are using the interactive spark-shell, the Spark driver instantiates the SparkSession for us, whereas if we are in a Spark application, we’ll create the SparkSession ourselves. 
We’ll look at examples of both in the lessons ahead.

### Executor
Executors are the worker processes that execute the code assigned to them by the driver process and report the state of 
the computation on that executor back to the driver.

Once the resources have been allocated, the Driver directly communicates with the executors. 
In most deployment modes a single executor runs per node. 
Spark executors are assigned tasks that require working on a subset of data located closest to them in the cluster. 
Working on data in close proximity is referred to as data locality and helps reduce the consumption of network bandwidth.

![image](https://user-images.githubusercontent.com/33947539/183057054-073a8b58-0b76-4eb9-969e-47e11438969a.png)

### Cluster manager#
A MapReduce or a Spark job runs on a cluster of machines. 
MapReduce’s Application Master or Spark’s Driver process don’t have the authority or the ability to allocate cluster resources for job execution. 
Instead there’s another piece of software that manages the physical resources of the cluster and arbitrates them among jobs, 
usually based on some user-defined policy. The Spark driver has to negotiate resources with the cluster manager to launch executor processes. 
YARN is one such example of a cluster manager software. 
Spark is compatible with the following cluster managers:

Local mode

Built-in standalone cluster manager

Hadoop YARN

Kubernetes

Apache Mesos

## The Spark Cluster

Spark applications run as independent sets of processes on a cluster. These clusters are coordinated by the SparkContext object in the driver (main) program.

### To run on a cluster:

SparkContext must connect to multiple cluster managers that allocate resources across the application.
Once connected, Spark acquires executors on nodes in the clusters. These are processes that run and store the computations.
Spark then sends application code to the executors, and SparkContext sends tasks to the executors to run.
